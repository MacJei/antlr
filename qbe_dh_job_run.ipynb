{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QBE DATAHUB DIRECT JOB DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import path as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optparse import OptionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputScript():\n",
    "    def __init__(self, cntx, fname):\n",
    "        self.cntx = cntx\n",
    "        self.fname = fname\n",
    "        self.code = []\n",
    "\n",
    "    def addCode(self, code):\n",
    "        self.code.append(code)\n",
    "    \n",
    "    def printCode(self):\n",
    "        with open(self.cntx.target_dir + '\\\\' + self.fname, 'w') as f:        \n",
    "            for ln in self.code:\n",
    "                f.write(ln + \"\\n\")\n",
    "\n",
    "def startConversion(cntx):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseInputArgs():\n",
    "    usage = \"\"\"\\npython imwProcOffload.py \n",
    "                            [-O --tgtdir] <output dir>\n",
    "                            [-I --srcdir] <source dir>\"\"\"\n",
    "    \n",
    "    p = OptionParser(usage)\n",
    "    \n",
    "    p.add_option('-O', '--tgtdir', action='store', type='string', dest='target_dir', help=\"Loaction where output scripts will be stored\")\n",
    "    p.add_option('-I', '--srcdir', action='store', type='string', dest='source_dir', help=\"Loaction where input scripts are stored\")\n",
    "                \n",
    "    options, args = p.parse_args()\n",
    "    \n",
    "   \n",
    "    if options.source_dir == None:\n",
    "        p.error('Output location is required')     \n",
    "        return -1\n",
    "        \n",
    "    if len(args) > 0:\n",
    "        p.error('expecting zero argument, {} given'.format(len(args)))\n",
    "        return -1    \n",
    "    \n",
    "    argv = {'target_dir'    : options.target_dir,\n",
    "            'source_dir'    : options.source_dir\n",
    "        }\n",
    "    \n",
    "    return argv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertContext():\n",
    "    def __init__(self, in_arg):\n",
    "        self.source_dir = in_arg['source_dir']\n",
    "        self.target_dir = in_arg['target_dir']\n",
    "\n",
    "    def validate(self):\n",
    "        #todo\n",
    "        pass\n",
    "        \n",
    "    def showContext(self):\n",
    "        return ' '*28 + 'source_dir : ' + self.source_dir + \"\\n\" + ' '*28 + \\\n",
    "               'target_dir : ' + self.target_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startConversion(cntx):\n",
    "    for file in os.listdir(cntx.source_dir):\n",
    "        in_file_path = cntx.source_dir + '\\\\' + file\n",
    "        \n",
    "        if not os.path.isfile(in_file_path):\n",
    "            continue\n",
    "       \n",
    "        try:\n",
    "                    in_script = SqlServerScript.TSQL(cntx, file)\n",
    "                    cnv = SqlServerConvert(cntx, in_script)\n",
    "                    out_script = cnv.convert()\n",
    "                    out_script.printCode() \n",
    "                    cntx.logger.print_log()\n",
    "\n",
    "        except Exception as e:\n",
    "            cntx.logger.add_log('ERROR', 'Unable to process file ' + in_file_path)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: \n",
      "python imwProcOffload.py \n",
      "                            [-O --tgtdir] <output dir>\n",
      "                            [-I --srcdir] <source dir>\n",
      "\n",
      "ipykernel_launcher.py: error: no such option: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "input = parseInputArgs()\n",
    "cntx = ConvertContext(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= 'C:\\\\Qbe\\\\SIT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trace_07_23_2019_21_36_03_2__6394f0b1_86a9_4d55_93eb_e06a4071dc60.txt\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(path):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last line is:\n",
      "(14.2) 07-25-19 08:20:28 (7284:1384)      JOB: Job <JOB_ETL_All_DataHub> is completed successfully.\n",
      "\n",
      "The first line is:\n",
      "(14.2) 07-23-19 21:36:04 (7284:1384)      JOB: Current system configuration : <SIT4_DIRECT>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    f=open('C:\\\\Qbe\\\\trace_07_23_2019_21_36_03_2__6394f0b1_86a9_4d55_93eb_e06a4071dc60.txt','r')\n",
    "    #data=f.read()\n",
    "    lineList = f.readlines()\n",
    "    f.close()\n",
    "    print(\"The last line is:\")\n",
    "    print(lineList[-1])\n",
    "    print(\"The first line is:\")\n",
    "    print(lineList[0])\n",
    "    lstln=lineList[-1]\n",
    "    fstln=lineList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=re.search(r'completed successfully',lstln,re.S|re.I).group().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed successfully'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-25-19 08:20:28\n"
     ]
    }
   ],
   "source": [
    "enddate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I).group().strip()\n",
    "print(enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOB_ETL_All_DataHub'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobnm=re.search(r'(?<=Job)\\s.*<\\w+>',job,re.S|re.I).group().strip()\n",
    "jobnm=re.sub('<','',jobnm)\n",
    "jobnm=re.sub('>','',jobnm)\n",
    "jobnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-23-19 21:36:04\n"
     ]
    }
   ],
   "source": [
    "startdate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I).group().strip()\n",
    "print(startdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_tbl_dc['Job_Name']=jobnm\n",
    "direct_tbl_dc['Start_Date']=startdate\n",
    "direct_tbl_dc['End_Date']=enddate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_tbl_dc={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Job_Name': 'JOB_ETL_All_DataHub',\n",
       " 'Start_Date': '07-23-19 21:36:04',\n",
       " 'End_Date': '07-25-19 08:20:28'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_tbl_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Job_Name         Start_Date           End_Date\n",
      "0  JOB_ETL_All_DataHub  07-23-19 21:36:04  07-25-19 08:20:28\n"
     ]
    }
   ],
   "source": [
    "#direct_tbl = pd.DataFrame(direct_tbl_dc,index=)\n",
    "\n",
    "#direct_tbl=pd.DataFrame.from_dict(direct_tbl_dc,orient='index',columns=direct_tbl_dc.keys())\n",
    "\n",
    "df= pd.DataFrame([direct_tbl_dc.values()],columns=direct_tbl_dc.keys())\n",
    "#df.columns= ['Job_Name', 'Start_Date','End_Date']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path= 'C:\\\\Qbe\\\\SIT'\n",
    "direct_tbl_dc={}\n",
    "lst_nm=[]\n",
    "lst_sd=[]\n",
    "lst_ed=[]\n",
    "for filename in os.listdir(path):\n",
    "    #f=open('C:\\\\Qbe\\\\trace_07_23_2019_21_36_03_2__6394f0b1_86a9_4d55_93eb_e06a4071dc60.txt','r')\n",
    "    #with open(path+'\\\\'+filename,'r') as f:\n",
    "    #data=f.read()\n",
    "        f=open(path+'\\\\'+filename,'r')\n",
    "        lineList = f.readlines()\n",
    "        #print(lineList)\n",
    "        #f.close()\n",
    "        #print(\"The last line is:\")\n",
    "        #print(lineList[-1])\n",
    "        #print(\"The first line is:\")\n",
    "        #print(lineList[0])\n",
    "        lstln=lineList[-1]\n",
    "        fstln=lineList[0]\n",
    "        #print(re.search(r'completed successfully',lstln,re.S|re.I))\n",
    "        if re.search(r'completed successfully',lstln,re.S|re.I):\n",
    "            enddate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I).group().strip()\n",
    "            #print(enddate)  \n",
    "            #enddate1=filter(lambda x: x!=NoneType, list(enddate)) \n",
    "            enddate1=(x for x in enddate if x != None)\n",
    "            jobnm=re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I).group().strip()\n",
    "            jobnm=re.sub('<','',jobnm)\n",
    "            jobnm=re.sub('>','',jobnm)\n",
    "            jobnm1=(x for x in jobnm if x != None)\n",
    "            \n",
    "            #print(jobnm1)\n",
    "            #jobnm=jobnm.replace(None,'a')\n",
    "            #jobnm1=filter(None,jobnm)\n",
    "            startdate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I).group().strip()\n",
    "            startdate1=(x for x in startdate if x != None)\n",
    "#             direct_tbl_dc['Job_Name']=jobnm\n",
    "#             direct_tbl_dc['Start_Date']=lst_sd.append(startdate)\n",
    "#             direct_tbl_dc['End_Date']=lst_ed.append(enddate1)\n",
    "            #print(jobnm)\n",
    "            #print(direct_tbl_dc) \n",
    "            #lst_nm=lst_nm.append(jobnm1)\n",
    "            print(jobnm1)\n",
    "            print(startdate1)\n",
    "            print(enddate1)\n",
    "            #lst_sd=lst_sd.append(startdate1)\n",
    "            #lst_ed=lst_ed.append(enddate1)\n",
    "            \n",
    "           # files= pd.DataFrame([{'job_name':lst_nm,'Start_Date':lst_sd}],columns=['job_name', 'Start_Date'])\n",
    "            #print(direct_tbl_dc)\n",
    "        else:\n",
    "              continue\n",
    "#print(direct_tbl_dc)           \n",
    "#files= pd.DataFrame([direct_tbl_dc.values()],columns=direct_tbl_dc.keys())\n",
    "#print(files)\n",
    "# print(            lst_nm,\n",
    "#             lst_sd,\n",
    "#             lst_ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_name</th>\n",
       "      <th>Start_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  job_name Start_Date\n",
       "0     None       None"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path= 'C:\\\\Qbe\\\\SIT'\n",
    "direct_tbl_dc={}\n",
    "lst_nm=[]\n",
    "lst_sd=[]\n",
    "lst_ed=[]\n",
    "lst_st=[]\n",
    "lst_flnm=[]\n",
    "for filename in os.listdir(path):\n",
    "    #f=open('C:\\\\Qbe\\\\trace_07_23_2019_21_36_03_2__6394f0b1_86a9_4d55_93eb_e06a4071dc60.txt','r')\n",
    "    #with open(path+'\\\\'+filename,'r') as f:\n",
    "    #data=f.read()\n",
    "        f=open(path+'\\\\'+filename,'r')\n",
    "        lineList = f.readlines()\n",
    "        #print(lineList)\n",
    "        #f.close()\n",
    "        #print(\"The last line is:\")\n",
    "        #print(lineList[-1])\n",
    "        #print(\"The first line is:\")\n",
    "        #print(lineList[0])\n",
    "        lstln=lineList[-1]\n",
    "        fstln=lineList[0]\n",
    "        #print(re.search(r'completed successfully',lstln,re.S|re.I))\n",
    "        if re.search(r'completed successfully',lstln,re.S|re.I):\n",
    "            if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I):\n",
    "                enddate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I).group().strip()\n",
    "            else:\n",
    "                enddate='N/A'\n",
    "            #print(enddate)  \n",
    "            #enddate1=filter(lambda x: x!=NoneType, list(enddate)) \n",
    "            enddate1=(x for x in enddate if x != None)\n",
    "            if re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I):\n",
    "                jobnm=re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I).group().strip()\n",
    "                jobnm=re.sub('<','',jobnm)\n",
    "                jobnm=re.sub('>','',jobnm)\n",
    "            #jobnm1=(x for x in jobnm if x != None)\n",
    "            else:\n",
    "                jobnm='N/A'\n",
    "            #jobnm=jobnm.replace(None,'a')\n",
    "            #jobnm1=filter(None,jobnm)\n",
    "            if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I):\n",
    "                startdate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I).group().strip()\n",
    "            else:\n",
    "                startdate='N/A'\n",
    "            status='success'\n",
    "            #startdate1=(x for x in startdate if x != None)\n",
    "#             direct_tbl_dc['Job_Name']=jobnm\n",
    "#             direct_tbl_dc['Start_Date']=lst_sd.append(startdate)\n",
    "#             direct_tbl_dc['End_Date']=lst_ed.append(enddate1)\n",
    "            #print(jobnm)\n",
    "            #print(direct_tbl_dc) \n",
    "            #lst_nm=lst_nm.append(jobnm1)\n",
    "#             print(jobnm1)\n",
    "#             print(startdate1)\n",
    "#             print(enddate1)\n",
    "           # files= pd.DataFrame([{'job_name':lst_nm,'Start_Date':lst_sd}],columns=['job_name', 'Start_Date'])\n",
    "            #print(direct_tbl_dc)\n",
    "        elif re.search(r'terminated due to error',lstln,re.S|re.I):\n",
    "                    #err=re.search(r'terminated due to error',err,re.S|re.I).group().search()\n",
    "                    if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I):\n",
    "                        enddate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I).group().strip()\n",
    "                    else:\n",
    "                        enddate='N/A'\n",
    "                    if re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I):\n",
    "                        #jobnm=re.search(r'(?<=Job)\\s.*<\\w>?',lstln,re.S|re.I).group().strip()\n",
    "                        jobnm=re.search(r'(?<=Job)\\s+<(\\w+)>',err).group().strip()\n",
    "                        jobnm=re.sub('<','',jobnm)\n",
    "                        jobnm=re.sub('>','',jobnm)\n",
    "                    else:\n",
    "                        jobnm='N/A'\n",
    "                    if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I):\n",
    "                        startdate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I).group().strip()\n",
    "                    else:\n",
    "                        startdate='N/A'\n",
    "                    status='failure'\n",
    "        else:\n",
    "                    if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I):\n",
    "                        enddate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I).group().strip()\n",
    "                    else:\n",
    "                        enddate='N/A'\n",
    "                    if re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I):\n",
    "                        #jobnm=re.search(r'(?<=Job)\\s.*<\\w>?',lstln,re.S|re.I).group().strip()\n",
    "                        jobnm=re.search(r'(?<=Job)\\s+<(\\w+)>',err).group().strip()\n",
    "                        jobnm=re.sub('<','',jobnm)\n",
    "                        jobnm=re.sub('>','',jobnm)\n",
    "                    else:\n",
    "                        jobnm='N/A'\n",
    "                    if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I):\n",
    "                        startdate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I).group().strip()\n",
    "                    else:\n",
    "                        startdate='N/A'\n",
    "                    status=re.search(r'(?<=DATAFLOW:)\\s.*(\\w.*)',flow).group().strip()\n",
    "        lst_sd.append(startdate)\n",
    "        lst_ed.append(enddate)\n",
    "        lst_nm.append(jobnm)\n",
    "        lst_st.append(status)\n",
    "        lst_flnm.append(filename)\n",
    "                        \n",
    "direct_tbl_dc['Job_Name']=lst_nm\n",
    "direct_tbl_dc['Start_Date']=lst_sd\n",
    "direct_tbl_dc['End_Date']=lst_ed\n",
    "direct_tbl_dc['Status']=lst_st\n",
    "direct_tbl_dc['File_Name']=lst_flnm\n",
    "#print(direct_tbl_dc)           \n",
    "#files= pd.DataFrame([direct_tbl_dc.values()],columns=direct_tbl_dc.keys())\n",
    "#print(files)\n",
    "#file_wr=open(\"C:\\\\Qbe\\\\SIT_Output.txt\",\"w\")\n",
    "#files.to_csv(\"C:\\\\Qbe\\\\SIT_Out.csv\", header=False, index=False)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_lst=pd.DataFrame.from_dict(direct_tbl_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_lst.to_csv(\"C:\\\\Qbe\\\\SIT_Out.csv\", header=True, index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= 'C:\\\\Qbe\\\\UAT'\n",
    "direct_tbl_dc={}\n",
    "lst_nm=[]\n",
    "lst_sd=[]\n",
    "lst_ed=[]\n",
    "lst_st=[]\n",
    "lst_flnm=[]\n",
    "for filename in os.listdir(path):\n",
    "    #f=open('C:\\\\Qbe\\\\trace_07_23_2019_21_36_03_2__6394f0b1_86a9_4d55_93eb_e06a4071dc60.txt','r')\n",
    "    #with open(path+'\\\\'+filename,'r') as f:\n",
    "    #data=f.read()\n",
    "        f=open(path+'\\\\'+filename,'r')\n",
    "        lineList = f.readlines()\n",
    "        #print(lineList)\n",
    "        #f.close()\n",
    "        #print(\"The last line is:\")\n",
    "        #print(lineList[-1])\n",
    "        #print(\"The first line is:\")\n",
    "        #print(lineList[0])\n",
    "        lstln=lineList[-1]\n",
    "        fstln=lineList[0]\n",
    "        #print(re.search(r'completed successfully',lstln,re.S|re.I))\n",
    "        if re.search(r'completed successfully',lstln,re.S|re.I):\n",
    "            if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I):\n",
    "                enddate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I).group().strip()\n",
    "            else:\n",
    "                enddate='N/A'\n",
    "            #print(enddate)  \n",
    "            #enddate1=filter(lambda x: x!=NoneType, list(enddate)) \n",
    "            enddate1=(x for x in enddate if x != None)\n",
    "            if re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I):\n",
    "                jobnm=re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I).group().strip()\n",
    "                jobnm=re.sub('<','',jobnm)\n",
    "                jobnm=re.sub('>','',jobnm)\n",
    "            #jobnm1=(x for x in jobnm if x != None)\n",
    "            else:\n",
    "                jobnm='N/A'\n",
    "            #jobnm=jobnm.replace(None,'a')\n",
    "            #jobnm1=filter(None,jobnm)\n",
    "            if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I):\n",
    "                startdate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I).group().strip()\n",
    "            else:\n",
    "                startdate='N/A'\n",
    "            status='success'\n",
    "            #startdate1=(x for x in startdate if x != None)\n",
    "#             direct_tbl_dc['Job_Name']=jobnm\n",
    "#             direct_tbl_dc['Start_Date']=lst_sd.append(startdate)\n",
    "#             direct_tbl_dc['End_Date']=lst_ed.append(enddate1)\n",
    "            #print(jobnm)\n",
    "            #print(direct_tbl_dc) \n",
    "            #lst_nm=lst_nm.append(jobnm1)\n",
    "#             print(jobnm1)\n",
    "#             print(startdate1)\n",
    "#             print(enddate1)\n",
    "           # files= pd.DataFrame([{'job_name':lst_nm,'Start_Date':lst_sd}],columns=['job_name', 'Start_Date'])\n",
    "            #print(direct_tbl_dc)\n",
    "        elif re.search(r'terminated due to error',lstln,re.S|re.I):\n",
    "                    #err=re.search(r'terminated due to error',err,re.S|re.I).group().search()\n",
    "                    if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I):\n",
    "                        enddate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I).group().strip()\n",
    "                    else:\n",
    "                        enddate='N/A'\n",
    "                    if re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I):\n",
    "                        #jobnm=re.search(r'(?<=Job)\\s.*<\\w>?',lstln,re.S|re.I).group().strip()\n",
    "                        jobnm=re.search(r'(?<=Job)\\s+<(\\w+)>',err).group().strip()\n",
    "                        jobnm=re.sub('<','',jobnm)\n",
    "                        jobnm=re.sub('>','',jobnm)\n",
    "                    else:\n",
    "                        jobnm='N/A'\n",
    "                    if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I):\n",
    "                        startdate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I).group().strip()\n",
    "                    else:\n",
    "                        startdate='N/A'\n",
    "                    status='failure'\n",
    "        else:\n",
    "                    if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I):\n",
    "                        enddate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',lstln,re.S|re.I).group().strip()\n",
    "                    else:\n",
    "                        enddate='N/A'\n",
    "                    if re.search(r'(?<=Job)\\s.*<\\w+>',lstln,re.S|re.I):\n",
    "                        #jobnm=re.search(r'(?<=Job)\\s.*<\\w>?',lstln,re.S|re.I).group().strip()\n",
    "                        jobnm=re.search(r'(?<=Job)\\s+<(\\w+)>',err).group().strip()\n",
    "                        jobnm=re.sub('<','',jobnm)\n",
    "                        jobnm=re.sub('>','',jobnm)\n",
    "                    else:\n",
    "                        jobnm='N/A'\n",
    "                    if re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I):\n",
    "                        startdate=re.search(r'\\d{2}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',fstln,re.S|re.I).group().strip()\n",
    "                    else:\n",
    "                        startdate='N/A'\n",
    "                    status=re.search(r'(?<=DATAFLOW:)\\s.*(\\w.*)',flow).group().strip()\n",
    "        lst_sd.append(startdate)\n",
    "        lst_ed.append(enddate)\n",
    "        lst_nm.append(jobnm)\n",
    "        lst_st.append(status)\n",
    "        lst_flnm.append(filename)\n",
    "                        \n",
    "direct_tbl_dc['Job_Name']=lst_nm\n",
    "direct_tbl_dc['Start_Date']=lst_sd\n",
    "direct_tbl_dc['End_Date']=lst_ed\n",
    "direct_tbl_dc['Status']=lst_st\n",
    "direct_tbl_dc['File_Name']=lst_flnm\n",
    "files_lst=pd.DataFrame.from_dict(direct_tbl_dc) \n",
    "files_lst.to_csv(\"C:\\\\Qbe\\\\UAT_Out.csv\", header=True, index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
